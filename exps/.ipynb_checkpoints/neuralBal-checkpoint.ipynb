{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class SingleLayerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleLayerNN, self).__init__()\n",
    "        self.fc = nn.Linear(1, 1000)  \n",
    "        self.fc2 = nn.Linear(1000, 250)\n",
    "        self.out = nn.Linear(250, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc(x)) \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.out(x)  \n",
    "        return x\n",
    "\n",
    "model = SingleLayerNN()\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralBalance(inl, oul, rand = False, freq=1.0, order=1):\n",
    "    shape = inl.weight.shape[0]\n",
    "    norm = []\n",
    "    \n",
    "    if rand:\n",
    "        ind = int(freq*shape)\n",
    "        ind = np.random.choice(shape, ind, replace = False)\n",
    "        indt = torch.from_numpy(ind).long()\n",
    "\n",
    "        prev = torch.linalg.norm(inl.weight[indt], dim=1, ord=order)\n",
    "        out = torch.linalg.norm(oul.weight[:,indt], dim = 0, ord=order)\n",
    "\n",
    "        opt = torch.sqrt(prev/out)\n",
    "        inl.weight[indt].data = inl.weight[indt.data]*opt.unsqueeze(1)\n",
    "        oul.weight[:,indt].data = oul.weight[:,indt.data]/opt\n",
    "\n",
    "    else:\n",
    "        prev = torch.linalg.norm(inl.weight, dim = 1, ord=order)\n",
    "        out = torch.linalg.norm(oul.weight, dim = 0, ord=order)\n",
    "\n",
    "        opt = torch.sqrt(prev/out)\n",
    "        inl.weight.data = inl.weight*opt.unsqueeze(1)\n",
    "        oul.weight.data = oul.weight/opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\n",
      "Linear\n",
      "Linear\n",
      "Epoch 0/10000, Loss: 0.8931108713150024\n",
      "Epoch 50/10000, Loss: 0.4697255790233612\n",
      "Epoch 100/10000, Loss: 0.3528272211551666\n",
      "Epoch 150/10000, Loss: 0.3362120985984802\n",
      "Epoch 200/10000, Loss: 0.32078325748443604\n",
      "Epoch 250/10000, Loss: 0.2829120457172394\n",
      "Epoch 300/10000, Loss: 0.2499542385339737\n",
      "Epoch 350/10000, Loss: 0.20755387842655182\n",
      "Epoch 400/10000, Loss: 0.14059138298034668\n",
      "Epoch 450/10000, Loss: 0.08393199741840363\n",
      "Epoch 500/10000, Loss: 0.06924621760845184\n",
      "Epoch 550/10000, Loss: 0.06795312464237213\n",
      "Epoch 600/10000, Loss: 0.06745658814907074\n",
      "Epoch 650/10000, Loss: 0.06717836856842041\n",
      "Epoch 700/10000, Loss: 0.06645341217517853\n",
      "Epoch 750/10000, Loss: 0.06586474180221558\n",
      "Epoch 800/10000, Loss: 0.06522048264741898\n",
      "Epoch 850/10000, Loss: 0.0644008219242096\n",
      "Epoch 900/10000, Loss: 0.07140237092971802\n",
      "Epoch 950/10000, Loss: 0.06264408677816391\n",
      "Epoch 1000/10000, Loss: 0.07085748761892319\n",
      "Epoch 1050/10000, Loss: 0.06028979644179344\n",
      "Epoch 1100/10000, Loss: 0.0622529461979866\n",
      "Epoch 1150/10000, Loss: 0.057601604610681534\n",
      "Epoch 1200/10000, Loss: 0.0554211288690567\n",
      "Epoch 1250/10000, Loss: 0.06708872318267822\n",
      "Epoch 1300/10000, Loss: 0.052922189235687256\n",
      "Epoch 1350/10000, Loss: 0.04998144134879112\n",
      "Epoch 1400/10000, Loss: 0.046583142131567\n",
      "Epoch 1450/10000, Loss: 0.09615293145179749\n",
      "Epoch 1500/10000, Loss: 0.05156298354268074\n",
      "Epoch 1550/10000, Loss: 2751.827392578125\n",
      "Epoch 1600/10000, Loss: 259.37603759765625\n",
      "Epoch 1650/10000, Loss: 70.12067413330078\n",
      "Epoch 1700/10000, Loss: 39.184940338134766\n",
      "Epoch 1750/10000, Loss: 29.516286849975586\n",
      "Epoch 1800/10000, Loss: 25.16431999206543\n",
      "Epoch 1850/10000, Loss: 22.976558685302734\n",
      "Epoch 1900/10000, Loss: 21.53510093688965\n",
      "Epoch 1950/10000, Loss: 20.390817642211914\n",
      "Epoch 2000/10000, Loss: 19.327308654785156\n",
      "Epoch 2050/10000, Loss: 1.996989461417951e+24\n",
      "Epoch 2100/10000, Loss: 1.9968949218545733e+24\n",
      "Epoch 2150/10000, Loss: 1.9968217113390308e+24\n",
      "Epoch 2200/10000, Loss: 1.9967852501964476e+24\n",
      "Epoch 2250/10000, Loss: 1.9967780444370438e+24\n",
      "Epoch 2300/10000, Loss: 1.9967712710232042e+24\n",
      "Epoch 2350/10000, Loss: 1.996764929954929e+24\n",
      "Epoch 2400/10000, Loss: 1.9967591653474059e+24\n",
      "Epoch 2450/10000, Loss: 1.9967534007398828e+24\n",
      "Epoch 2500/10000, Loss: 1.996747924362736e+24\n",
      "Epoch 2550/10000, Loss: nan\n",
      "Epoch 2600/10000, Loss: nan\n",
      "Epoch 2650/10000, Loss: nan\n",
      "Epoch 2700/10000, Loss: nan\n",
      "Epoch 2750/10000, Loss: nan\n",
      "Epoch 2800/10000, Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-903099834c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "X = torch.linspace(0, 4 * np.pi, 1000).unsqueeze(-1)  \n",
    "Y = torch.sin(X)  \n",
    "\n",
    "lay = []\n",
    "for n, i in model.named_children():\n",
    "    print(type(i).__name__)\n",
    "    if type(i).__name__ == \"Linear\":\n",
    "        lay.append((n, i))\n",
    "\n",
    "num_epochs = 10000  \n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad() \n",
    "    outputs = model(X)  \n",
    "    loss = criterion(outputs, Y) \n",
    "\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    \n",
    "    if epoch % 500 == 0 and epoch > 1000:\n",
    "        for i in range(len(lay)):\n",
    "            if i > 0:\n",
    "                neuralBalance(lay[i-1][1], lay[i][1], rand=False, freq = 1, order=1)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "plt.title('Wavy Pattern')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicted = model(X).data.numpy()\n",
    "\n",
    "plt.scatter(X, Y, label='Original data', alpha=0.6)\n",
    "plt.plot(X, predicted, label='Fitted line', color='red')\n",
    "plt.legend()\n",
    "plt.title('Neural Network Model vs Original Data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_weights = model.fc.weight.detach().numpy().flatten()\n",
    "fc2_weights = model.fc2.weight.detach().numpy().flatten()\n",
    "out_weights = model.out.weight.detach().numpy().flatten()\n",
    "\n",
    "bins = np.linspace(-0.5, 0.5, 50) \n",
    "fc_hist, fc_bins = np.histogram(fc_weights, bins=bins)\n",
    "fc2_hist, fc2_bins = np.histogram(fc2_weights, bins=bins)\n",
    "out_hist, out_bins = np.histogram(out_weights, bins=bins)\n",
    "\n",
    "fc_bin_centers = 0.5 * (fc_bins[:-1] + fc_bins[1:])\n",
    "fc2_bin_centers = 0.5 * (fc2_bins[:-1] + fc2_bins[1:])\n",
    "out_bin_centers = 0.5 * (out_bins[:-1] + out_bins[1:])\n",
    "\n",
    "plt.figure(figsize=(25, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fc_bin_centers, fc_hist, marker='o', linestyle='-', color='b')\n",
    "plt.title('Weight Distribution: Input to Hidden1 Layer')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(out_bin_centers, out_hist, marker='o', linestyle='-', color='r')\n",
    "plt.title('Weight Distribution: Hidden1 to Hidden2 Layer')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(fc2_bin_centers, fc2_hist, marker='o', linestyle='-', color='g')\n",
    "plt.title('Weight Distribution: Hidden2 to Output Layer')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero weights greater than 0.01 in layer 1: 986\n",
      "Number of non-zero weights greater than 0.01 in layer 2: 213206\n",
      "Number of non-zero weights greater than 0.01 in layer 3: 198\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def count_nonzero_weights_above_threshold(layer, threshold=0.1):\n",
    "    return torch.sum(torch.abs(layer.weight) > threshold).item()\n",
    "\n",
    "threshold_value = 0.01 \n",
    "\n",
    "nonzero_fc1 = count_nonzero_weights_above_threshold(model.fc, threshold=threshold_value)\n",
    "nonzero_fc2 = count_nonzero_weights_above_threshold(model.fc2, threshold=threshold_value)\n",
    "nonzero_fc3 = count_nonzero_weights_above_threshold(model.out, threshold=threshold_value)\n",
    "\n",
    "print(f'Number of non-zero weights greater than {threshold_value} in layer 1: {nonzero_fc1}')\n",
    "print(f'Number of non-zero weights greater than {threshold_value} in layer 2: {nonzero_fc2}')\n",
    "print(f'Number of non-zero weights greater than {threshold_value} in layer 3: {nonzero_fc3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
